---
apiVersion: v1
kind: ConfigMap
metadata:
  name: serviceaccount-infra-csi
  namespace: default
  annotations:
    projectsveltos.io/template: "true"
data:
  rbac.yaml: |
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
      namespace: "{{ .Cluster.metadata.namespace }}"
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: Role
    metadata:
      name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
      namespace: "{{ .Cluster.metadata.namespace }}"
    rules:
    - apiGroups: ["cdi.kubevirt.io"]
      resources: ["datavolumes"]
      verbs: ["get", "create", "delete"]
    - apiGroups: ["kubevirt.io"]
      resources: ["virtualmachineinstances"]
      verbs: ["list", "get"]
    - apiGroups: ["subresources.kubevirt.io"]
      resources: ["virtualmachineinstances/addvolume", "virtualmachineinstances/removevolume"]
      verbs: ["update"]
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: RoleBinding
    metadata:
      name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
      namespace: "{{ .Cluster.metadata.namespace }}"
    roleRef:
      apiGroup: rbac.authorization.k8s.io
      kind: Role
      name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
      apiGroup: rbac.authorization.k8s.io
    subjects:
    - kind: ServiceAccount
      name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
      namespace: "{{ .Cluster.metadata.namespace }}"
    ---
    apiVersion: v1
    kind: Secret
    metadata:
      name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
      namespace: "{{ .Cluster.metadata.namespace }}"
      annotations:
        kubernetes.io/service-account.name: "{{ .Cluster.metadata.name }}-kubevirt-csi"
    type: kubernetes.io/service-account-token
---
# BUG https://github.com/projectsveltos/addon-controller/issues/465
apiVersion: v1
kind: ConfigMap
metadata:
  name: controller-tenant-csi-kubeconfig
  namespace: default
  annotations:
    projectsveltos.io/template: "true"
data:
  default.yaml: |
    apiVersion: v1
    kind: Secret
    metadata:
      name: csi-kubeconfig-external
      namespace: kubevirt-csi-driver
    stringData: 
      mgmt-kubeconfig: |
        apiVersion: v1
        kind: Config
        clusters:
        - name: managment-cluster
          cluster:
            certificate-authority-data: {{ $data:=(index .MgtmResources  "csi").data }} {{ (index $data "ca.crt") }}
            server: "https://${MASTER_PUBLIC_IP}:6443"
        contexts:
        - name: managment-cluster
          context:
            cluster: managment-cluster
            user: managment-cluster
        current-context: managment-cluster
        users:
        - name: managment-cluster
          user:
            token: {{ (index .MgtmResources  "csi").data.token | b64dec }}

---
apiVersion: v1
kind: ConfigMap
metadata:
  name: controller-tenant-csi-controller
  namespace: default
  annotations:
    projectsveltos.io/template: "true"
data:
  deployment.yaml: |
    ---
    kind: Deployment
    apiVersion: apps/v1
    metadata:
      name: kubevirt-csi-controller
      namespace: kubevirt-csi-driver
    spec:
      replicas: 1
      selector:
        matchLabels:
          app: kubevirt-csi-driver
      template:
        metadata:
          labels:
            app: kubevirt-csi-driver
        spec:
          serviceAccount: kubevirt-csi-controller-sa
          priorityClassName: system-cluster-critical
          nodeSelector:
            node-role.kubernetes.io/control-plane: ""
          tolerations:
            - key: CriticalAddonsOnly
              operator: Exists
            - key: node-role.kubernetes.io/master
              operator: Exists
              effect: "NoSchedule"
            - key: node-role.kubernetes.io/control-plane
              operator: Exists
              effect: "NoSchedule"
          containers:
            - name: csi-driver
              imagePullPolicy: Always
              #image: quay.io/kubevirt/csi-driver:latest
              image: lukasmrtvy/kubevirt-csi-driver:7aa580f8933c1ffb54f12aa5985781fa7e84f308
              args:
                - "--endpoint=$(CSI_ENDPOINT)"
                - "--infra-cluster-namespace=$(INFRACLUSTER_NAMESPACE)"
                - "--infra-cluster-kubeconfig=/var/run/secrets/infracluster/mgmt-kubeconfig"
                - "--infra-cluster-labels=$(INFRACLUSTER_LABELS)"
                - "--run-node-service=false"
                - "--run-controller-service=true"
                - --v=999
              ports:
                - name: healthz
                  containerPort: 10301
                  protocol: TCP
              env:
                - name: CSI_ENDPOINT
                  value: unix:///var/lib/csi/sockets/pluginproxy/csi.sock
                - name: KUBE_NODE_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: spec.nodeName
                - name: INFRACLUSTER_NAMESPACE
                  valueFrom:
                    configMapKeyRef:
                      name: driver-config
                      key: infraClusterNamespace
                - name: INFRACLUSTER_LABELS
                  valueFrom:
                    configMapKeyRef:
                      name: driver-config
                      key: infraClusterLabels
                - name: INFRA_STORAGE_CLASS_ENFORCEMENT
                  valueFrom:
                    configMapKeyRef:
                      name: driver-config
                      key: infraStorageClassEnforcement
                      optional: true
              volumeMounts:
                - name: socket-dir
                  mountPath: /var/lib/csi/sockets/pluginproxy/
                - name: infracluster
                  mountPath: "/var/run/secrets/infracluster"
              resources:
                requests:
                  memory: 50Mi
                  cpu: 10m
            - name: csi-provisioner
              image: quay.io/openshift/origin-csi-external-provisioner:latest
              args:
                - --csi-address=$(ADDRESS)
                - --default-fstype=ext4
                - --timeout=5m
                - --retry-interval-max=1m
                - --v=5
              env:
                - name: ADDRESS
                  value: /var/lib/csi/sockets/pluginproxy/csi.sock
              volumeMounts:
                - name: socket-dir
                  mountPath: /var/lib/csi/sockets/pluginproxy/
            - name: csi-attacher
              image: quay.io/openshift/origin-csi-external-attacher:latest
              args:
                - --csi-address=$(ADDRESS)
                - --timeout=5m
                - --retry-interval-max=1m
                - --v=5
              env:
                - name: ADDRESS
                  value: /var/lib/csi/sockets/pluginproxy/csi.sock
              volumeMounts:
                - name: socket-dir
                  mountPath: /var/lib/csi/sockets/pluginproxy/
              resources:
                requests:
                  memory: 50Mi
                  cpu: 10m
            - name: csi-liveness-probe
              image: quay.io/openshift/origin-csi-livenessprobe:latest
              args:
                - --csi-address=/csi/csi.sock
                - --probe-timeout=3s
                - --health-port=10301
              volumeMounts:
                - name: socket-dir
                  mountPath: /csi
              resources:
                requests:
                  memory: 50Mi
                  cpu: 10m
          volumes:
            - name: socket-dir
              emptyDir: {}
            - name: infracluster
              secret:
                secretName: csi-kubeconfig-external
    ---
    apiVersion: v1
    kind: ConfigMap
    metadata:
      name: driver-config
      namespace: kubevirt-csi-driver
    data:
      infraClusterNamespace: "{{ .Cluster.metadata.namespace }}"
      #infraClusterLabels: "csi-driver/cluster={{ .Cluster.metadata.name }}"
      #infraClusterLabels: "name={{ .Cluster.metadata.name }}"
      infraClusterLabels: "cluster.x-k8s.io/cluster-name={{ .Cluster.metadata.name }}"
      #infraStorageClassEnforcement: longhorn-hdd
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: controller-tenant-csi-node
  namespace: default
  annotations:
    projectsveltos.io/template: "true"
data:
  deployment.yaml: |
    apiVersion: storage.k8s.io/v1
    kind: CSIDriver
    metadata:
      name: csi.kubevirt.io
    spec:
      attachRequired: true
      podInfoOnMount: true
      fsGroupPolicy: ReadWriteOnceWithFSType
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: kubevirt-csi-controller-sa
      namespace: kubevirt-csi-driver
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: kubevirt-csi-controller-cr
    rules:
      - apiGroups: ['']
        resources: ['persistentvolumes']
        verbs: ['create', 'delete', 'get', 'list', 'watch', 'update', 'patch']
      - apiGroups: ['']
        resources: ['secrets']
        verbs: ['get', 'list']
      - apiGroups: ['']
        resources: ['persistentvolumeclaims']
        verbs: ['get', 'list', 'watch', 'update']
      - apiGroups: [""]
        resources: ["persistentvolumeclaims/status"]
        verbs: ["update", "patch"]
      - apiGroups: ['']
        resources: ['nodes']
        verbs: ['get', 'list', 'watch']
      - apiGroups: ['storage.k8s.io']
        resources: ['volumeattachments']
        verbs: ['get', 'list', 'watch', 'update', 'patch']
      - apiGroups: ['storage.k8s.io']
        resources: ['storageclasses']
        verbs: ['get', 'list', 'watch']
      - apiGroups: ['csi.storage.k8s.io']
        resources: ['csidrivers']
        verbs: ['get', 'list', 'watch', 'update', 'create']
      - apiGroups: ['']
        resources: ['events']
        verbs: ['list', 'watch', 'create', 'update', 'patch']
      - apiGroups: ["snapshot.storage.k8s.io"]
        resources: ["volumesnapshotclasses"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["snapshot.storage.k8s.io"]
        resources: ["volumesnapshotcontents"]
        verbs: ["create", "get", "list", "watch", "update", "delete"]
      - apiGroups: ["snapshot.storage.k8s.io"]
        resources: ["volumesnapshots"]
        verbs: ["get", "list", "watch", "update"]
      - apiGroups: ["snapshot.storage.k8s.io"]
        resources: ["volumesnapshots/status"]
        verbs: ["update"]
      - apiGroups: [ "storage.k8s.io" ]
        resources: [ "volumeattachments/status" ]
        verbs: [ "get", "list", "watch", "update", "patch" ]
      - apiGroups: ["storage.k8s.io"]
        resources: ["csinodes"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["security.openshift.io"]
        resources: ["securitycontextconstraints"]
        verbs: ["use"]
        resourceNames: ["privileged"]
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: kubevirt-csi-controller-binding
    subjects:
      - kind: ServiceAccount
        name: kubevirt-csi-controller-sa
        namespace: kubevirt-csi-driver
    roleRef:
      kind: ClusterRole
      name: kubevirt-csi-controller-cr
      apiGroup: rbac.authorization.k8s.io
    ---
    apiVersion: v1
    kind: ServiceAccount
    metadata:
      name: kubevirt-csi-node-sa
      namespace: kubevirt-csi-driver
    ---
    apiVersion: rbac.authorization.k8s.io/v1
    kind: ClusterRole
    metadata:
      name: kubevirt-csi-node-cr
    rules:
      - apiGroups: [""]
        resources: ["persistentvolumes"]
        verbs: ["get", "list", "watch", "update", "create", "delete"]
      - apiGroups: [""]
        resources: ["persistentvolumeclaims"]
        verbs: ["get", "list", "watch", "update"]
      - apiGroups: ["storage.k8s.io"]
        resources: ["storageclasses"]
        verbs: ["get", "list", "watch"]
      - apiGroups: [""]
        resources: ["nodes"]
        verbs: ["get", "list", "watch", "update", "patch"]
      - apiGroups: ["csi.storage.k8s.io"]
        resources: ["csinodeinfos"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["storage.k8s.io"]
        resources: ["csinodes"]
        verbs: ["get", "list", "watch"]
      - apiGroups: ["storage.k8s.io"]
        resources: ["volumeattachments"]
        verbs: ["get", "list", "watch", "update"]
      - apiGroups: ["storage.k8s.io"]
        resources: ["volumeattachments/status"]
        verbs: ["get", "list", "watch", "update", "patch"]
      - apiGroups: [""]
        resources: ["events"]
        verbs: ["list", "watch", "create", "update", "patch"]
      - apiGroups: ["security.openshift.io"]
        resources: ["securitycontextconstraints"]
        verbs: ["use"]
        resourceNames: ["privileged"]
    ---
    kind: ClusterRoleBinding
    apiVersion: rbac.authorization.k8s.io/v1
    metadata:
      name: kubevirt-csi-node-binding
    subjects:
      - kind: ServiceAccount
        name: kubevirt-csi-node-sa
        namespace: kubevirt-csi-driver
    roleRef:
      kind: ClusterRole
      name: kubevirt-csi-node-cr
      apiGroup: rbac.authorization.k8s.io
    ---
    kind: DaemonSet
    apiVersion: apps/v1
    metadata:
      name: kubevirt-csi-node
      namespace: kubevirt-csi-driver
    spec:
      selector:
        matchLabels:
          app: kubevirt-csi-driver
      updateStrategy:
        type: RollingUpdate
      template:
        metadata:
          labels:
            app: kubevirt-csi-driver
        spec:
          serviceAccount: kubevirt-csi-node-sa
          priorityClassName: system-node-critical
          tolerations:
            - operator: Exists
          containers:
            - name: csi-driver
              securityContext:
                privileged: true
                allowPrivilegeEscalation: true
              imagePullPolicy: Always
              #image: quay.io/kubevirt/csi-driver:latest
              image: lukasmrtvy/kubevirt-csi-driver:7aa580f8933c1ffb54f12aa5985781fa7e84f308
              args:
                - "--endpoint=unix:/csi/csi.sock"
                - "--node-name=$(KUBE_NODE_NAME)"
                - "--run-node-service=true"
                - "--run-controller-service=false"
                - "--v=9"
              env:
                - name: KUBE_NODE_NAME
                  valueFrom:
                    fieldRef:
                      fieldPath: spec.nodeName
              volumeMounts:
                - name: kubelet-dir
                  mountPath: /var/lib/kubelet
                  mountPropagation: "Bidirectional"
                - name: plugin-dir
                  mountPath: /csi
                - name: device-dir
                  mountPath: /dev
                - name: udev
                  mountPath: /run/udev
              ports:
                - name: healthz
                  containerPort: 10300
                  protocol: TCP
              livenessProbe:
                httpGet:
                  path: /healthz
                  port: healthz
                initialDelaySeconds: 10
                timeoutSeconds: 3
                periodSeconds: 10
                failureThreshold: 5
              resources:
                requests:
                  memory: 50Mi
                  cpu: 10m
            - name: csi-node-driver-registrar
              image: quay.io/openshift/origin-csi-node-driver-registrar:latest
              args:
                - "--csi-address=$(ADDRESS)"
                - "--kubelet-registration-path=$(DRIVER_REG_SOCK_PATH)"
                - "--v=5"
              lifecycle:
                preStop:
                  exec:
                    command: ["/bin/sh", "-c", "rm -rf /registration/csi.kubevirt.io-reg.sock /csi/csi.sock"]
              env:
                - name: ADDRESS
                  value: /csi/csi.sock
                - name: DRIVER_REG_SOCK_PATH
                  value: /var/lib/kubelet/plugins/csi.kubevirt.io/csi.sock
              volumeMounts:
                - name: plugin-dir
                  mountPath: /csi
                - name: registration-dir
                  mountPath: /registration
              resources:
                requests:
                  memory: 20Mi
                  cpu: 5m
            - name: csi-liveness-probe
              image: quay.io/openshift/origin-csi-livenessprobe:latest
              args:
                - "--csi-address=/csi/csi.sock"
                - "--probe-timeout=3s"
                - "--health-port=10300"
              volumeMounts:
                - name: plugin-dir
                  mountPath: /csi
              resources:
                requests:
                  memory: 20Mi
                  cpu: 5m
          volumes:
            - name: kubelet-dir
              hostPath:
                path: /var/lib/kubelet
                type: Directory
            - name: plugin-dir
              hostPath:
                path: /var/lib/kubelet/plugins/csi.kubevirt.io/
                type: DirectoryOrCreate
            - name: registration-dir
              hostPath:
                path: /var/lib/kubelet/plugins_registry/
                type: Directory
            - name: device-dir
              hostPath:
                path: /dev
                type: Directory
            - name: udev
              hostPath:
                path: /run/udev
    ---
    apiVersion: storage.k8s.io/v1
    kind: StorageClass
    metadata:
      name: kubevirt
      annotations:
        storageclass.kubernetes.io/is-default-class: "true"
    provisioner: csi.kubevirt.io
    parameters:
      infraStorageClassName: longhorn-hdd
      bus: scsi
